{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "ðŸ“ŠStock Market Analysis ðŸ“ˆ + Prediction using LSTM",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shikha-2609/StockPrice-Predictor_And_Analysis/blob/main/%F0%9F%93%8AStock_Market_Analysis_%F0%9F%93%88_%2B_Prediction_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'tesla-stock-price:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1007%2F1814%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T055821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9034786bf83bdc70e6454b861d151c798b273e2d7154c5b512b5eff66b77119f53f1d84b61b8a7722924ee69952b3559dd34ce8bbf18db90e438f5511abce3ee9de1e5e91a6385bef4d01895e0ac5f5d572194318f218e3aeb75a7ae0e1b636f8e93c45962caf2ce39e8eda0072bb37160b6949fc499d2abe7e3c6e7f997d68c3dbbbe47c60fb8ddccbecec9a1e530d0d6c57e138ac1649cf49545acbda9645b678bc02e75b3c2697826c6798815a37863096db9a0038242bcf51b68f001a2e45cc423d9979815acec4659c8c874e3e20e046151c8eca4c66451a16f6e10d2df65f07e3ec4e09b0f85b54e56e3180e1adb5e7728bc9605a9e4f9c453c2848acd,sandp500:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1908%2F17155%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T055821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dad5ca6e23adc0dfb00f109223966bf67c1f13ebe3690677531acf7e7062895c81a9df2932b6935a7f3405947a4a5cf0488f4027196a45e681eef422879761310be9eb5220f2a687dc848817c058a67ceec751a152d5db92afe8def1109ddf701f9d9bb77e94b6886f9c364032d9eddde53ded76873ebf0b9d108e63ceed770d72942e1198e07ded6d6a382714ea521fe04e0ded095f3949818968db1b862a3d087cb63540251ed0248d6cdc45e021688e9a623811d16cb350d3e81a4fa365103e723b109bd955dd5dceeeccd0d62ff431be8da1d7c9a6435d60e5a4c2879380b851897c4b583ffe378e903fbf6e64f2ae87531e222a1b5f0bbb68ec7ee4485e9,amzn-dpz-btc-ntfx-adjusted-may-2013may2019:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F195545%2F433077%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T055821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3bbb4c81e435f3e4d824e8306cfef8470fdebf77677d1b8e19922a7b2a3a379548628ee0cc7e36fe5a3b34f7c680fa0be8f5989ef3242f0502782642106a55b8c3bedb022f26b2800d7827e73b79eec5fe06762bb48896f5b8eb0ae729bec65aa0917f7d3c6219c0198b2ced018a13b1511a25d587eeb8a6f3b4cdb8ff97a2843c77fe76ce834ecf47dbd1b37a148535f5d00bb6baedba4aaf78857216e282b61a362457cb4e66713a7112b815784c70d6174f00b7a449a8bac5f6d2ada856dd7cd7f8569bcd239ad23727168a0aab1a1d7e7ebd680d7f7b58f8b4a8cfb950eac60e2d49581c581c521868162209c2947e799140c0bb6887fcf8ae9ce888a92d,apple-aapl-historical-stock-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F533900%2F976925%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T055821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4d910ca29f1cd14cd573ebf8b3e8635f6c5445dce7c1b41dfa2addc3aa853c4b4fa688afb2bd88edc807f585e4139365bfec94e18ace236e4a82b3b6b771d75ddccb122f2e052071dcc5076ed8dc5be90275165fe2006f1ca48194de35f54624acb9aa1c6b4709d48c08a3b5a1dd166241780ec38f703db8f0ee18303abcf18dc60f5da2d62657519e5a6d2664810d167f13b11c02232f889ca78fa3bb42e559cdc6e3a4423a7e091d49ee0317b399bd9b97d636563a7698fb9bb0cf100d82f6060b54c60e4f70fe8d129111ef060289e899c62dcb322447aa2eb8dc741607decdb331bdc4565d3c210d70367bfadfb9e55768fbf9f474fa4ded62a1e045cc57'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WdqaaCpp-dST"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Project - Stock Market Analysis\n"
      ],
      "metadata": {
        "id": "oIEpq3i0-dSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Series data is a series of data points indexed in time order. Time series data is everywhere, so manipulating them is important for any data analyst or data scientist.\n",
        "\n",
        "In this notebook, we will discover and explore data from the stock market, particularly some technology stocks (Apple, Amazon, Google, and Microsoft). We will learn how to use yfinance to get stock information, and visualize different aspects of it using Seaborn and Matplotlib. we will look at a few ways of analyzing the risk of a stock, based on its previous performance history. We will also be predicting future stock prices through a Long Short Term Memory (LSTM) method!\n",
        "\n",
        "We'll be answering the following questions along the way:\n",
        "\n",
        "    1.) What was the change in price of the stock over time?\n",
        "    2.) What was the daily return of the stock on average?\n",
        "    3.) What was the moving average of the various stocks?\n",
        "    4.) What was the correlation between different stocks'?\n",
        "    5.) How much value do we put at risk by investing in a particular stock?\n",
        "    6.) How can we attempt to predict future stock behavior? (Predicting the closing price stock price of APPLE inc using LSTM)\n",
        "\n",
        "***   \n",
        "\n",
        "## Getting the Data\n",
        "The first step is to get the data and load it to memory. We will get our stock data from the Yahoo Finance website. Yahoo Finance is a rich resource of financial market data and tools to find compelling investments. To get the data from Yahoo Finance, we will be using yfinance library which offers a threaded and Pythonic way to download market data from Yahoo. Check this article to learn more about yfinance: [Reliably download historical market data from with Python](https://aroussi.com/post/python-yahoo-finance)"
      ],
      "metadata": {
        "id": "UwnR6eac-dSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What was the change in price of the stock overtime?\n",
        "\n",
        "In this section we'll go over how to handle requesting stock information with pandas, and how to analyze basic attributes of a stock."
      ],
      "metadata": {
        "id": "oTK9pdRu-dSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q yfinance"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:03.549762Z",
          "iopub.execute_input": "2023-01-30T22:53:03.550933Z",
          "iopub.status.idle": "2023-01-30T22:53:15.422877Z",
          "shell.execute_reply.started": "2023-01-30T22:53:03.55086Z",
          "shell.execute_reply": "2023-01-30T22:53:15.421628Z"
        },
        "trusted": true,
        "id": "3AmaFfYj-dSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%matplotlib inline\n",
        "\n",
        "# For reading stock data from yahoo\n",
        "from pandas_datareader.data import DataReader\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "yf.pdr_override()\n",
        "\n",
        "# For time stamps\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# The tech stocks we'll use for this analysis\n",
        "tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
        "\n",
        "# Set up End and Start times for data grab\n",
        "tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
        "\n",
        "end = datetime.now()\n",
        "start = datetime(end.year - 1, end.month, end.day)\n",
        "\n",
        "for stock in tech_list:\n",
        "    globals()[stock] = yf.download(stock, start, end)\n",
        "\n",
        "\n",
        "company_list = [AAPL, GOOG, MSFT, AMZN]\n",
        "company_name = [\"APPLE\", \"GOOGLE\", \"MICROSOFT\", \"AMAZON\"]\n",
        "\n",
        "for company, com_name in zip(company_list, company_name):\n",
        "    company[\"company_name\"] = com_name\n",
        "\n",
        "df = pd.concat(company_list, axis=0)\n",
        "df.tail(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:15.425689Z",
          "iopub.execute_input": "2023-01-30T22:53:15.426113Z",
          "iopub.status.idle": "2023-01-30T22:53:16.973427Z",
          "shell.execute_reply.started": "2023-01-30T22:53:15.426073Z",
          "shell.execute_reply": "2023-01-30T22:53:16.972202Z"
        },
        "trusted": true,
        "id": "PinvCTh1-dSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reviewing the content of our data, we can see that the data is numeric and the date is the index of the data. Notice also that weekends are missing from the records.\n",
        "\n",
        "**Quick note:** Using `globals()` is a sloppy way of setting the `DataFrame` names, but it's simple. Now we have our data, let's perform some basic data analysis and check our data."
      ],
      "metadata": {
        "id": "ABvHmOae-dSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Statistics about the Data\n",
        "`.describe()` generates descriptive statistics. Descriptive statistics include those that summarize the central tendency, dispersion, and shape of a datasetâ€™s distribution, excluding `NaN` values.\n",
        "\n",
        "Analyzes both numeric and object series, as well as `DataFrame` column sets of mixed data types. The output will vary depending on what is provided. Refer to the notes below for more detail."
      ],
      "metadata": {
        "id": "LWYW7eUz-dSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary Stats\n",
        "AAPL.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:16.975716Z",
          "iopub.execute_input": "2023-01-30T22:53:16.976539Z",
          "iopub.status.idle": "2023-01-30T22:53:17.010551Z",
          "shell.execute_reply.started": "2023-01-30T22:53:16.9765Z",
          "shell.execute_reply": "2023-01-30T22:53:17.00843Z"
        },
        "trusted": true,
        "id": "NLVkAjw6-dSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have only 255 records in one year because weekends are not included in the data."
      ],
      "metadata": {
        "id": "tzm7DVjD-dSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information About the Data\n",
        "`.info()` method prints information about a DataFrame including the index `dtype` and columns, non-null values, and memory usage."
      ],
      "metadata": {
        "id": "qFuzaXRD-dSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General info\n",
        "AAPL.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:17.013734Z",
          "iopub.execute_input": "2023-01-30T22:53:17.014269Z",
          "iopub.status.idle": "2023-01-30T22:53:17.029859Z",
          "shell.execute_reply.started": "2023-01-30T22:53:17.014233Z",
          "shell.execute_reply": "2023-01-30T22:53:17.028404Z"
        },
        "trusted": true,
        "id": "IT8Em-01-dSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closing Price\n",
        "\n",
        "The closing price is the last price at which the stock is traded during the regular trading day. A stockâ€™s closing price is the standard benchmark used by investors to track its performance over time."
      ],
      "metadata": {
        "id": "BjoThAdb-dSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see a historical view of the closing price\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplots_adjust(top=1.25, bottom=1.2)\n",
        "\n",
        "for i, company in enumerate(company_list, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    company['Adj Close'].plot()\n",
        "    plt.ylabel('Adj Close')\n",
        "    plt.xlabel(None)\n",
        "    plt.title(f\"Closing Price of {tech_list[i - 1]}\")\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:17.031469Z",
          "iopub.execute_input": "2023-01-30T22:53:17.034665Z",
          "iopub.status.idle": "2023-01-30T22:53:18.532404Z",
          "shell.execute_reply.started": "2023-01-30T22:53:17.034609Z",
          "shell.execute_reply": "2023-01-30T22:53:18.530872Z"
        },
        "trusted": true,
        "id": "3WICHdpC-dSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Volume of Sales\n",
        "Volume is the amount of an asset or security that changes hands over some period of time, often over the course of a day. For instance, the stock trading volume would refer to the number of shares of security traded between its daily open and close. Trading volume, and changes to volume over the course of time, are important inputs for technical traders."
      ],
      "metadata": {
        "id": "eeNj5uss-dSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's plot the total volume of stock being traded each day\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplots_adjust(top=1.25, bottom=1.2)\n",
        "\n",
        "for i, company in enumerate(company_list, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    company['Volume'].plot()\n",
        "    plt.ylabel('Volume')\n",
        "    plt.xlabel(None)\n",
        "    plt.title(f\"Sales Volume for {tech_list[i - 1]}\")\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:18.534332Z",
          "iopub.execute_input": "2023-01-30T22:53:18.534757Z",
          "iopub.status.idle": "2023-01-30T22:53:20.063873Z",
          "shell.execute_reply.started": "2023-01-30T22:53:18.534721Z",
          "shell.execute_reply": "2023-01-30T22:53:20.062686Z"
        },
        "trusted": true,
        "id": "oQzpAOA_-dSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've seen the visualizations for the closing price and the volume traded each day, let's go ahead and caculate the moving average for the stock."
      ],
      "metadata": {
        "id": "If-9QZvG-dSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. What was the moving average of the various stocks?\n",
        "\n",
        "The moving average (MA) is a simple technical analysis tool that smooths out price data by creating a constantly updated average price. The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks, or any time period the trader chooses."
      ],
      "metadata": {
        "id": "bnBOOSx7-dSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ma_day = [10, 20, 50]\n",
        "\n",
        "for ma in ma_day:\n",
        "    for company in company_list:\n",
        "        column_name = f\"MA for {ma} days\"\n",
        "        company[column_name] = company['Adj Close'].rolling(ma).mean()\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        "\n",
        "AAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])\n",
        "axes[0,0].set_title('APPLE')\n",
        "\n",
        "GOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])\n",
        "axes[0,1].set_title('GOOGLE')\n",
        "\n",
        "MSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])\n",
        "axes[1,0].set_title('MICROSOFT')\n",
        "\n",
        "AMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])\n",
        "axes[1,1].set_title('AMAZON')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:20.065607Z",
          "iopub.execute_input": "2023-01-30T22:53:20.066321Z",
          "iopub.status.idle": "2023-01-30T22:53:22.167966Z",
          "shell.execute_reply.started": "2023-01-30T22:53:20.066274Z",
          "shell.execute_reply": "2023-01-30T22:53:22.166773Z"
        },
        "trusted": true,
        "id": "M6QnnG3N-dSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see in the graph that the best values to measure the moving average are 10 and 20 days because we still capture trends in the data without noise."
      ],
      "metadata": {
        "id": "saQizFSR-dS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. What was the daily return of the stock on average?"
      ],
      "metadata": {
        "id": "KzKOtwQZ-dS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've done some baseline analysis, let's go ahead and dive a little deeper. We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value. Let's go ahead and use pandas to retrieve teh daily returns for the Apple stock."
      ],
      "metadata": {
        "id": "zylVv5B8-dS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use pct_change to find the percent change for each day\n",
        "for company in company_list:\n",
        "    company['Daily Return'] = company['Adj Close'].pct_change()\n",
        "\n",
        "# Then we'll plot the daily return percentage\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        "\n",
        "AAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\n",
        "axes[0,0].set_title('APPLE')\n",
        "\n",
        "GOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')\n",
        "axes[0,1].set_title('GOOGLE')\n",
        "\n",
        "MSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')\n",
        "axes[1,0].set_title('MICROSOFT')\n",
        "\n",
        "AMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')\n",
        "axes[1,1].set_title('AMAZON')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:22.169469Z",
          "iopub.execute_input": "2023-01-30T22:53:22.170167Z",
          "iopub.status.idle": "2023-01-30T22:53:23.76016Z",
          "shell.execute_reply.started": "2023-01-30T22:53:22.170126Z",
          "shell.execute_reply": "2023-01-30T22:53:23.758438Z"
        },
        "trusted": true,
        "id": "iED5NJoE-dS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now let's get an overall look at the average daily return using a histogram. We'll use seaborn to create both a histogram and kde plot on the same figure."
      ],
      "metadata": {
        "id": "4L90msAR-dS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "for i, company in enumerate(company_list, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    company['Daily Return'].hist(bins=50)\n",
        "    plt.xlabel('Daily Return')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.title(f'{company_name[i - 1]}')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:23.762096Z",
          "iopub.execute_input": "2023-01-30T22:53:23.762497Z",
          "iopub.status.idle": "2023-01-30T22:53:25.223946Z",
          "shell.execute_reply.started": "2023-01-30T22:53:23.762465Z",
          "shell.execute_reply": "2023-01-30T22:53:25.222884Z"
        },
        "trusted": true,
        "id": "dURag_Uv-dS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. What was the correlation between different stocks closing prices?"
      ],
      "metadata": {
        "id": "kK1t1oNk-dS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation is a statistic that measures the degree to which two variables move in relation to each other which has a value that must fall between -1.0 and +1.0. Correlation measures association, but doesnâ€™t show if x causes y or vice versa â€” or if the association is caused by a third factor[1].\n",
        "\n",
        "Now what if we wanted to analyze the returns of all the stocks in our list? Let's go ahead and build a DataFrame with all the ['Close'] columns for each of the stocks dataframes."
      ],
      "metadata": {
        "id": "9csUMF4R-dS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab all the closing prices for the tech stock list into one DataFrame\n",
        "\n",
        "closing_df = pdr.get_data_yahoo(tech_list, start=start, end=end)['Adj Close']\n",
        "\n",
        "# Make a new tech returns DataFrame\n",
        "tech_rets = closing_df.pct_change()\n",
        "tech_rets.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:25.2276Z",
          "iopub.execute_input": "2023-01-30T22:53:25.228619Z",
          "iopub.status.idle": "2023-01-30T22:53:25.672267Z",
          "shell.execute_reply.started": "2023-01-30T22:53:25.228575Z",
          "shell.execute_reply": "2023-01-30T22:53:25.670437Z"
        },
        "trusted": true,
        "id": "hxyp0qjx-dS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compare the daily percentage return of two stocks to check how correlated. First let's see a sotck compared to itself."
      ],
      "metadata": {
        "id": "dw-Rb6cW-dS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing Google to itself should show a perfectly linear relationship\n",
        "sns.jointplot(x='GOOG', y='GOOG', data=tech_rets, kind='scatter', color='seagreen')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:25.674373Z",
          "iopub.execute_input": "2023-01-30T22:53:25.674901Z",
          "iopub.status.idle": "2023-01-30T22:53:26.430112Z",
          "shell.execute_reply.started": "2023-01-30T22:53:25.674841Z",
          "shell.execute_reply": "2023-01-30T22:53:26.428883Z"
        },
        "trusted": true,
        "id": "ee9J-g33-dS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use joinplot to compare the daily returns of Google and Microsoft\n",
        "sns.jointplot(x='GOOG', y='MSFT', data=tech_rets, kind='scatter')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:26.431785Z",
          "iopub.execute_input": "2023-01-30T22:53:26.433128Z",
          "iopub.status.idle": "2023-01-30T22:53:27.137587Z",
          "shell.execute_reply.started": "2023-01-30T22:53:26.433077Z",
          "shell.execute_reply": "2023-01-30T22:53:27.136302Z"
        },
        "trusted": true,
        "id": "P5KIGVSu-dS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we can see that if two stocks are perfectly (and positivley) correlated with each other a linear relationship bewteen its daily return values should occur.\n",
        "\n",
        "Seaborn and pandas make it very easy to repeat this comparison analysis for every possible combination of stocks in our technology stock ticker list. We can use sns.pairplot() to automatically create this plot"
      ],
      "metadata": {
        "id": "o5H4Cvl4-dS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can simply call pairplot on our DataFrame for an automatic visual analysis\n",
        "# of all the comparisons\n",
        "\n",
        "sns.pairplot(tech_rets, kind='reg')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:27.139622Z",
          "iopub.execute_input": "2023-01-30T22:53:27.139998Z",
          "iopub.status.idle": "2023-01-30T22:53:32.327777Z",
          "shell.execute_reply.started": "2023-01-30T22:53:27.139967Z",
          "shell.execute_reply": "2023-01-30T22:53:32.325975Z"
        },
        "trusted": true,
        "id": "sbNhub7T-dS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we can see all the relationships on daily returns between all the stocks. A quick glance shows an interesting correlation between Google and Amazon daily returns. It might be interesting to investigate that individual comaprison.\n",
        "\n",
        "While the simplicity of just calling `sns.pairplot()` is fantastic we can also use `sns.PairGrid()` for full control of the figure, including what kind of plots go in the diagonal, the upper triangle, and the lower triangle. Below is an example of utilizing the full power of seaborn to achieve this result."
      ],
      "metadata": {
        "id": "L8YxS3mz-dS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
        "return_fig = sns.PairGrid(tech_rets.dropna())\n",
        "\n",
        "# Using map_upper we can specify what the upper triangle will look like.\n",
        "return_fig.map_upper(plt.scatter, color='purple')\n",
        "\n",
        "# We can also define the lower triangle in the figure, inclufing the plot type (kde)\n",
        "# or the color map (BluePurple)\n",
        "return_fig.map_lower(sns.kdeplot, cmap='cool_d')\n",
        "\n",
        "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
        "return_fig.map_diag(plt.hist, bins=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:32.329737Z",
          "iopub.execute_input": "2023-01-30T22:53:32.330154Z",
          "iopub.status.idle": "2023-01-30T22:53:36.190698Z",
          "shell.execute_reply.started": "2023-01-30T22:53:32.33012Z",
          "shell.execute_reply": "2023-01-30T22:53:36.189487Z"
        },
        "trusted": true,
        "id": "5Y5xyrBE-dS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame\n",
        "returns_fig = sns.PairGrid(closing_df)\n",
        "\n",
        "# Using map_upper we can specify what the upper triangle will look like.\n",
        "returns_fig.map_upper(plt.scatter,color='purple')\n",
        "\n",
        "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
        "returns_fig.map_lower(sns.kdeplot,cmap='cool_d')\n",
        "\n",
        "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
        "returns_fig.map_diag(plt.hist,bins=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:36.191973Z",
          "iopub.execute_input": "2023-01-30T22:53:36.192306Z",
          "iopub.status.idle": "2023-01-30T22:53:40.501339Z",
          "shell.execute_reply.started": "2023-01-30T22:53:36.192275Z",
          "shell.execute_reply": "2023-01-30T22:53:40.50005Z"
        },
        "trusted": true,
        "id": "FMp7m10u-dS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we could also do a correlation plot, to get actual numerical values for the correlation between the stocks' daily return values. By comparing the closing prices, we see an interesting relationship between Microsoft and Apple."
      ],
      "metadata": {
        "id": "1Gjtzv2k-dS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.heatmap(tech_rets.corr(), annot=True, cmap='summer')\n",
        "plt.title('Correlation of stock return')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "sns.heatmap(closing_df.corr(), annot=True, cmap='summer')\n",
        "plt.title('Correlation of stock closing price')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:40.503245Z",
          "iopub.execute_input": "2023-01-30T22:53:40.504161Z",
          "iopub.status.idle": "2023-01-30T22:53:41.154687Z",
          "shell.execute_reply.started": "2023-01-30T22:53:40.504113Z",
          "shell.execute_reply": "2023-01-30T22:53:41.153398Z"
        },
        "trusted": true,
        "id": "6UuIaUpL-dS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like we suspected in our `PairPlot` we see here numerically and visually that Microsoft and Amazon had the strongest correlation of daily stock return. It's also interesting to see that all the technology comapnies are positively correlated."
      ],
      "metadata": {
        "id": "Z7Q04Hgk-dS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. How much value do we put at risk by investing in a particular stock?"
      ],
      "metadata": {
        "id": "9kfsWomA-dTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many ways we can quantify risk, one of the most basic ways using the information we've gathered on daily percentage returns is by comparing the expected return with the standard deviation of the daily returns."
      ],
      "metadata": {
        "id": "q11-Kys3-dTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rets = tech_rets.dropna()\n",
        "\n",
        "area = np.pi * 20\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(rets.mean(), rets.std(), s=area)\n",
        "plt.xlabel('Expected return')\n",
        "plt.ylabel('Risk')\n",
        "\n",
        "for label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n",
        "    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',\n",
        "                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:53:41.156429Z",
          "iopub.execute_input": "2023-01-30T22:53:41.156939Z",
          "iopub.status.idle": "2023-01-30T22:53:41.598482Z",
          "shell.execute_reply.started": "2023-01-30T22:53:41.156891Z",
          "shell.execute_reply": "2023-01-30T22:53:41.597219Z"
        },
        "trusted": true,
        "id": "yrtbczzc-dTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Predicting the closing price stock price of APPLE inc:"
      ],
      "metadata": {
        "id": "LiiQgK7N-dTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the stock quote\n",
        "df = pdr.get_data_yahoo('AAPL', start='2012-01-01', end=datetime.now())\n",
        "# Show teh data\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:21.092621Z",
          "iopub.execute_input": "2023-01-30T22:54:21.093063Z",
          "iopub.status.idle": "2023-01-30T22:54:21.730045Z",
          "shell.execute_reply.started": "2023-01-30T22:54:21.093029Z",
          "shell.execute_reply": "2023-01-30T22:54:21.728467Z"
        },
        "trusted": true,
        "id": "9pqH9itW-dTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "plt.title('Close Price History')\n",
        "plt.plot(df['Close'])\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:24.484162Z",
          "iopub.execute_input": "2023-01-30T22:54:24.484575Z",
          "iopub.status.idle": "2023-01-30T22:54:24.949002Z",
          "shell.execute_reply.started": "2023-01-30T22:54:24.484543Z",
          "shell.execute_reply": "2023-01-30T22:54:24.947341Z"
        },
        "trusted": true,
        "id": "s2emCCY0-dTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe with only the 'Close column\n",
        "data = df.filter(['Close'])\n",
        "# Convert the dataframe to a numpy array\n",
        "dataset = data.values\n",
        "# Get the number of rows to train the model on\n",
        "training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
        "\n",
        "training_data_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:25.696185Z",
          "iopub.execute_input": "2023-01-30T22:54:25.697256Z",
          "iopub.status.idle": "2023-01-30T22:54:25.705935Z",
          "shell.execute_reply.started": "2023-01-30T22:54:25.697213Z",
          "shell.execute_reply": "2023-01-30T22:54:25.704797Z"
        },
        "trusted": true,
        "id": "c3BH8TDW-dTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(dataset)\n",
        "\n",
        "scaled_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:26.922566Z",
          "iopub.execute_input": "2023-01-30T22:54:26.923513Z",
          "iopub.status.idle": "2023-01-30T22:54:27.008859Z",
          "shell.execute_reply.started": "2023-01-30T22:54:26.923473Z",
          "shell.execute_reply": "2023-01-30T22:54:27.007904Z"
        },
        "trusted": true,
        "id": "ayiqFvvg-dTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training data set\n",
        "# Create the scaled training data set\n",
        "train_data = scaled_data[0:int(training_data_len), :]\n",
        "# Split the data into x_train and y_train data sets\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60, len(train_data)):\n",
        "    x_train.append(train_data[i-60:i, 0])\n",
        "    y_train.append(train_data[i, 0])\n",
        "    if i<= 61:\n",
        "        print(x_train)\n",
        "        print(y_train)\n",
        "        print()\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "# Reshape the data\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "# x_train.shape"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:28.564506Z",
          "iopub.execute_input": "2023-01-30T22:54:28.565665Z",
          "iopub.status.idle": "2023-01-30T22:54:28.583517Z",
          "shell.execute_reply.started": "2023-01-30T22:54:28.565624Z",
          "shell.execute_reply": "2023-01-30T22:54:28.581937Z"
        },
        "trusted": true,
        "id": "ud0DWMvT-dTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:54:29.78365Z",
          "iopub.execute_input": "2023-01-30T22:54:29.785159Z",
          "iopub.status.idle": "2023-01-30T22:56:54.386331Z",
          "shell.execute_reply.started": "2023-01-30T22:54:29.785089Z",
          "shell.execute_reply": "2023-01-30T22:56:54.385391Z"
        },
        "trusted": true,
        "id": "qNQNdHPh-dTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the testing data set\n",
        "# Create a new array containing scaled values from index 1543 to 2002\n",
        "test_data = scaled_data[training_data_len - 60: , :]\n",
        "# Create the data sets x_test and y_test\n",
        "x_test = []\n",
        "y_test = dataset[training_data_len:, :]\n",
        "for i in range(60, len(test_data)):\n",
        "    x_test.append(test_data[i-60:i, 0])\n",
        "\n",
        "# Convert the data to a numpy array\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "# Reshape the data\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
        "\n",
        "# Get the models predicted price values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Get the root mean squared error (RMSE)\n",
        "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
        "rmse"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:56:54.387851Z",
          "iopub.execute_input": "2023-01-30T22:56:54.38823Z",
          "iopub.status.idle": "2023-01-30T22:56:55.516442Z",
          "shell.execute_reply.started": "2023-01-30T22:56:54.388197Z",
          "shell.execute_reply": "2023-01-30T22:56:55.515051Z"
        },
        "trusted": true,
        "id": "Lg866UPy-dTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "train = data[:training_data_len]\n",
        "valid = data[training_data_len:]\n",
        "valid['Predictions'] = predictions\n",
        "# Visualize the data\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.title('Model')\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
        "plt.plot(train['Close'])\n",
        "plt.plot(valid[['Close', 'Predictions']])\n",
        "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:56:55.519391Z",
          "iopub.execute_input": "2023-01-30T22:56:55.520239Z",
          "iopub.status.idle": "2023-01-30T22:56:56.035566Z",
          "shell.execute_reply.started": "2023-01-30T22:56:55.52019Z",
          "shell.execute_reply": "2023-01-30T22:56:56.034289Z"
        },
        "trusted": true,
        "id": "Braks1Gh-dTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the valid and predicted prices\n",
        "valid"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-30T22:56:56.037716Z",
          "iopub.execute_input": "2023-01-30T22:56:56.038718Z",
          "iopub.status.idle": "2023-01-30T22:56:56.054039Z",
          "shell.execute_reply.started": "2023-01-30T22:56:56.038679Z",
          "shell.execute_reply": "2023-01-30T22:56:56.052596Z"
        },
        "trusted": true,
        "id": "FGO-lI09-dTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "In this notebook, you discovered and explored stock data.\n",
        "\n",
        "Specifically, you learned:\n",
        "\n",
        "- How to load stock market data from the YAHOO Finance website using yfinance.\n",
        "- How to explore and visualize time-series data using Pandas, Matplotlib, and Seaborn.\n",
        "- How to measure the correlation between stocks.\n",
        "- How to measure the risk of investing in a particular stock.\n",
        "\n",
        "Do you have any questions?\n",
        "Ask your questions in the comments below and I will do my best to answer.\n",
        "\n",
        "References:\n",
        "https://www.investopedia.com/terms/c/correlation.asp\n",
        "[Jose Portilla Udemy Course: Learning Python for Data Analysis and Visualization](https://www.udemy.com/course/learning-python-for-data-analysis-and-visualization/)"
      ],
      "metadata": {
        "id": "KwxWTkcl-dTP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2uHSYws-dTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}